{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1，数据集准备\n",
    "\n",
    "\n",
    "数据集来自kaggle的dog vs cat主页（https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "data_path = './'\n",
    "train_dir_name = 'train'\n",
    "test_dir_name = 'test'\n",
    "\n",
    "## check if the train and  test data is exist\n",
    "if not isdir(data_path + train_dir_name):\n",
    "    if not isfile(data_path + train_dir_name + '.zip'):\n",
    "        print (\"Please download train.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(data_path + train_dir_name + '.zip') as azip:\n",
    "            print (\"Now to extract %s \" % (data_path + train_dir_name + '.zip'))\n",
    "            azip.extractall()\n",
    "    \n",
    "if not isdir(data_path + test_dir_name):\n",
    "    if not isfile(data_path + test_dir_name + '.zip'):\n",
    "        print (\"Please download test1.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(data_path + test_dir_name + '.zip') as azip:\n",
    "            print (\"Now to extract %s \" % (data_path + test_dir_name + '.zip'))\n",
    "            azip.extractall()\n",
    "print (\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1，将猫狗训练数据分开存放\n",
    "\n",
    "为了尽快实现想法，我打算采用Keras平台，因为Keras已经包含了众多知名的模型，并且可以很轻易地加载与训练权重。而且Keras也提供了很方便的工具（image generator）来帮助我们直接从硬盘加载图片到模型，这样不但减少了代码量，而且利用Keras自带的程序能够极大减少内存的浪费（相比于手动一次性加载到内存）。但是image generator需要图片已经根据类别放入不同的文件夹。所以接下来的事情就是将训练和测试样本按照类别放入不同的文件夹。采用软链接的方式可以节约硬盘和时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = data_path + train_dir_name\n",
    "test_dir = data_path + test_dir_name\n",
    "\n",
    "## get all train filenames and test filenames\n",
    "train_filenames = os.listdir(train_dir)\n",
    "test_filenames = os.listdir(test_dir)\n",
    "\n",
    "## get all dogs and cats\n",
    "cat_names = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "dog_names = filter(lambda x:x[:3] == 'dog', train_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在已经获得了文件名，现在需要另外建立一个文件夹，用于存储分开的猫狗图片。为了节省空间，这里采用建立软链接的方式来分开存储猫狗图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build all linkage complete!\n"
     ]
    }
   ],
   "source": [
    "## check if we did that\n",
    "test_link_path = './test_link'\n",
    "test_link_data = './test_link/data'\n",
    "\n",
    "train_link_path = './train_link'\n",
    "train_link_cat = './train_link/cat'\n",
    "train_link_dog = './train_link/dog'\n",
    "\n",
    "if not isdir(test_link_path):\n",
    "    print (\"Now to build %s!\" % (test_link_path))\n",
    "    os.makedirs(test_link_path)\n",
    "    os.symlink('../' + test_dir_name, test_link_data)\n",
    "    \n",
    "if not isdir(train_link_path):\n",
    "    print (\"Now to build %s!\" % (train_link_path))\n",
    "    os.makedirs(train_link_cat)\n",
    "    os.makedirs(train_link_dog)\n",
    "    ## create link for the image\n",
    "    for file in cat_names:\n",
    "        os.symlink('../../' + train_dir_name+'/'+file, train_link_cat+'/'+file)\n",
    "    for file in dog_names:\n",
    "        os.symlink('../../' + train_dir_name+'/'+file, train_link_dog+'/'+file)\n",
    "\n",
    "print (\"Build all linkage complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, 方案1--单个模型\n",
    "\n",
    "首先我想到的第一个方案就是单个模型，在计算机视觉领域，有许多已经被证明了非常好用的模型，比如inception，resnet等，所以我接下来就是依次尝试各个模型，看看实际的效果怎么样？能否达到毕业项目的要求？并且我会预训练模型来进行训练，而不是从头训练，因为这些模型都已经在庞大的分类数据集中进行了训练，已经学习了足够的用于常用物体分类的‘知识’，因为图像的基本‘知识’是可以通用的，所以我采用迁移学习来对模型进行‘微调’，而不是从头学起。我打算采用inceptionv3,resnet-50,xception这三个模型来进行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 resnet-50\n",
    "\n",
    "初步采用的模型是ResNet-50，所以我们就需要按照该模型的要求来对图片进行预处理。\n",
    "现在我们需要载入预训练的ResNet-50模型，并且，由于ResNet-50模型的输出是1000维的向量，而我们的功能是二分类，所以只需要输出单一的概率即可，所以需要替换掉原始的输出层换成我们的sigmoid激活函数，include_top=False就不会加载原模型的全连接层部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"avg_pool/AvgPool:0\", shape=(?, 1, 1, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import resnet50\n",
    "\n",
    "## resNet-50 do not need preprocessing, so the resNet_input_shape is not neccessary\n",
    "resNet_input_shape = (224,224,3)\n",
    "\n",
    "res_x = Input(shape=resNet_input_shape)\n",
    "res_x = Lambda(resnet50.preprocess_input)(res_x)\n",
    "res_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=res_x, input_shape=resNet_input_shape)\n",
    "\n",
    "print (res_model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们采用的预训练模型，暂时只是在ResNet-50上微调，不会对全连接层以外的其它层进行训练。所以如果每次都从上面的模型的输入端进行输入的话会产生很多重复的计算，显得不那么高效。那么这里有一个技巧，可以先把resnet-50模型的全连接层以前的输出向量（传说中的bottleneck features，以下均称为特征向量）预先计算并保存起来，由于只需要训练之后的全连接层，所以，将这些保存的特征向量作为样本，当做之后的全连接层的训练的输入就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./vect\n"
     ]
    }
   ],
   "source": [
    "vec_dir_name = \"vect/\"\n",
    "resnet_50_vec_name = 'resnet-50.h5'\n",
    "vec_dir_path = data_path + \"vect\"\n",
    "resnet_50_vec_path = data_path + vec_dir_name + resnet_50_vec_name\n",
    "print (vec_dir_path)\n",
    "if not isdir(vec_dir_path):\n",
    "    os.makedirs(vec_dir_path)\n",
    "    print (\"Make vector dir:%s\" % (vec_dir_path))\n",
    "    \n",
    "\"\"\"\n",
    "check if the resnet-50 vector file is exist\n",
    "\"\"\"\n",
    "if not isfile(resnet_50_vec_path):\n",
    "    with h5py.File(resnet_50_vec_path, 'w') as f:\n",
    "        print (\"creating vector!!\")\n",
    "        out = GlobalAveragePooling2D()(res_model.output)\n",
    "        res_vec_model = Model(inputs=res_model.input, outputs=out)\n",
    "        \n",
    "        ## save vector\n",
    "        gen = ImageDataGenerator()\n",
    "        test_gen = ImageDataGenerator()\n",
    "        \"\"\"\n",
    "        classes = ['cat', 'dog'] -- cat is 0, dog is 1, so we need write this\n",
    "        class_mode = None -- i will not use like 'fit_fitgenerator', so i do not need labels\n",
    "        shuffle = False -- it is unneccssary\n",
    "        batch_size = 64 \n",
    "        \"\"\"\n",
    "        image_size = (224,224)\n",
    "        train_generator = gen.flow_from_directory(train_link_path, image_size, color_mode='rgb', \\\n",
    "                                                  classes=['cat', 'dog'], class_mode=None, shuffle=False, batch_size=64)\n",
    "        test_generator = test_gen.flow_from_directory(test_link_path, image_size, color_mode='rgb', \\\n",
    "                                                  class_mode=None, shuffle=False, batch_size=64)        \n",
    "        \"\"\"\n",
    "        steps = None, by default, the steps = len(generator)\n",
    "        \"\"\"\n",
    "        vector = res_vec_model.predict_generator(train_generator)\n",
    "        test_vector = res_vec_model.predict_generator(test_generator)\n",
    "        \n",
    "        f.create_dataset('x_train', data=vector)\n",
    "        f.create_dataset(\"y_train\", data=train_generator.classes)\n",
    "        f.create_dataset(\"test\", data=test_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "现在直接读取保存的特征向量进行训练，参数如下，优化器采用Adam，学习速率采用默认的0.001，batch size为32，先训练20epoch看看结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 17s 848us/step - loss: 0.0758 - acc: 0.9722 - val_loss: 0.0370 - val_acc: 0.9864\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.0422 - acc: 0.9858 - val_loss: 0.0324 - val_acc: 0.9882\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0370 - acc: 0.9865 - val_loss: 0.0331 - val_acc: 0.9882\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.0352 - acc: 0.9870 - val_loss: 0.0300 - val_acc: 0.9878\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0318 - val_acc: 0.9880\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0335 - acc: 0.9879 - val_loss: 0.0276 - val_acc: 0.9902\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0307 - acc: 0.9897 - val_loss: 0.0312 - val_acc: 0.9894\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.0321 - acc: 0.9893 - val_loss: 0.0331 - val_acc: 0.9886\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0331 - acc: 0.9883 - val_loss: 0.0339 - val_acc: 0.9888\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0294 - acc: 0.9890 - val_loss: 0.0338 - val_acc: 0.9884\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0322 - val_acc: 0.9884\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0307 - acc: 0.9891 - val_loss: 0.0345 - val_acc: 0.9868\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0315 - acc: 0.9888 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 0.0313 - acc: 0.9890 - val_loss: 0.0303 - val_acc: 0.9902\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0319 - acc: 0.9890 - val_loss: 0.0306 - val_acc: 0.9894\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0314 - acc: 0.9888 - val_loss: 0.0345 - val_acc: 0.9894\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.0317 - val_acc: 0.9904\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.0317 - acc: 0.9891 - val_loss: 0.0347 - val_acc: 0.9884\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0294 - acc: 0.9900 - val_loss: 0.0340 - val_acc: 0.9890\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0293 - acc: 0.9909 - val_loss: 0.0422 - val_acc: 0.9854\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "with h5py.File(resnet_50_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.4)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='res_dense_1')(x)\n",
    "\n",
    "res_top_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "res_top_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = res_top_model.fit(x_train, y_train, batch_size=32, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果看起来还不错，待会儿再在测试集上得出结果提交到kaggle。其实在得到这个结果之前犯了一个错误，就是从文件中读取出来x_train和y_train之后，没有对样本进行shuffle。导致验证集的loss在0.2到0.7不断地跳动，我刚开始还以为只是模型的结构引起的过拟合，所以修改了dropout的rate，将其变大，也就是丢弃的几率变大。而且还在输出层对参数加了一个L2的正则化。但是几乎没有效果。所以我就意识到，可能不是模型的问题。然后在群上看他们聊天聊到shuffle，我恍然大悟，原来是我读出来的时候没有进行shuffle，现在就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_loss(hist, title='loss'):\n",
    "    # show the training and validation loss\n",
    "    plt.plot(hist.history['val_loss'], label=\"validation loss\")\n",
    "    plt.plot(hist.history['loss'], label=\"train loss\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def show_acc(hist, title='accuracy'):\n",
    "    # show the training and validation loss\n",
    "    plt.plot(hist.history['val_acc'], label=\"validation accuracy\")\n",
    "    plt.plot(hist.history['acc'], label=\"train accuracy\")\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练完了之后，应该对测试集进行预测，并且声称csv格式的结果文件提交kaggle，从而得到模型的得分。其实文档的格式很简单，就是对测试集的每张图片的预测结果（也就是这张图片是狗的概率，注意不是0或者1哟！是类似0.99  0.11之类的概率值！），我写了一个专门的接口函数来完成预测以及结果文件的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "test result file resnet-50.csv generated!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_test_result(model_obj, test_vec_path, image_size, model_name=\"\"):\n",
    "    with h5py.File(test_vec_path, 'r') as f:\n",
    "        x_test = np.array(f['test'])\n",
    "\n",
    "    pred_test = model_obj.predict(x_test)\n",
    "    pred_test = pred_test.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    df = pd.read_csv(\"sampleSubmission.csv\")\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    test_generator = gen.flow_from_directory(test_link_path, image_size, color_mode='rgb',\n",
    "                                             shuffle=False, batch_size=64, class_mode=None)\n",
    "\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "        #df.set_value(index-1, 'label', y_pred[i])\n",
    "        df.loc[index-1, 'label'] = pred_test[i]\n",
    "    \n",
    "    df.to_csv('%s.csv' % (model_name), index=None)\n",
    "    print ('test result file %s.csv generated!' % (model_name))\n",
    "    df.head(10)\n",
    "\n",
    "get_test_result(res_top_model, resnet_50_vec_path, (224, 224), model_name=\"resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次提交了kaggle之后，loss为0.053。resnet-50模型先暂时不试了。先把模型参数和参数保存起来。由于是预训练模型，所以就不需要保存resnet-50部分，只保存添加的输出层参数就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_top_model.save('resnet-50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 inceptionv3\n",
    "\n",
    "接下尝试的是inceptionv3模型。因为以后还会尝试更多的模型，所以这里需要写一个通用的函数，而不是像之前resnet那样很分散。下面这个函数用于各种模型的特征向量的提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "def model_vector_catch(MODEL, image_size, file_name, preprocessing=None):\n",
    "    vec_dir = 'vect/'\n",
    "\n",
    "    input_tensor = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    if preprocessing:\n",
    "        ## check if need preprocessing\n",
    "        input_tensor = Lambda(preprocessing)(input_tensor)\n",
    "    model_no_top = MODEL(include_top=False, weights='imagenet', input_tensor=input_tensor, input_shape=(image_size[0], image_size[1], 3))\n",
    "    ## flatten the output shape and generate model\n",
    "    out = GlobalAveragePooling2D()(model_no_top.output)\n",
    "    new_model = Model(inputs=model_no_top.input, outputs=out)\n",
    "    \n",
    "    ## get iamge generator\n",
    "    gen = ImageDataGenerator()\n",
    "    test_gen = ImageDataGenerator()\n",
    "    \"\"\"\n",
    "    classes = ['cat', 'dog'] -- cat is 0, dog is 1, so we need write this\n",
    "    class_mode = None -- i will not use like 'fit_fitgenerator', so i do not need labels\n",
    "    shuffle = False -- it is unneccssary\n",
    "    batch_size = 64 \n",
    "    \"\"\"\n",
    "    train_generator = gen.flow_from_directory(train_link_path, image_size, color_mode='rgb', \\\n",
    "                                              classes=['cat', 'dog'], class_mode=None, shuffle=False, batch_size=64)\n",
    "    test_generator = test_gen.flow_from_directory(test_link_path, image_size, color_mode='rgb', \\\n",
    "                                          class_mode=None, shuffle=False, batch_size=64)\n",
    "    \"\"\"\n",
    "    steps = None, by default, the steps = len(generator)\n",
    "    \"\"\"\n",
    "    train_vector = new_model.predict_generator(train_generator)\n",
    "    test_vector = new_model.predict_generator(test_generator)\n",
    "    \n",
    "    with h5py.File(vec_dir + (\"%s.h5\" % (file_name)), 'w') as f: \n",
    "        f.create_dataset('x_train', data=train_vector)\n",
    "        f.create_dataset(\"y_train\", data=train_generator.classes)\n",
    "        f.create_dataset(\"test\", data=test_vector)\n",
    "    print (\"Model %s vector cached complete!\" % (file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Model inceptionv3 vector cached complete!\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "\n",
    "inceptionv3_vec_path = 'vect/inceptionv3.h5'\n",
    "\n",
    "if not isfile(inceptionv3_vec_path):\n",
    "    model_vector_catch(inception_v3.InceptionV3, (299, 299), 'inceptionv3', inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，我们先搭建模型，然后进行迁移学习。由于inceptionv3在全连接层之前的输出维度是(?, 1, 1, 2048)，所以新搭建的模型的输入维度是2048.\n",
    "\n",
    "inception v3论文上说其训练时候采用的是RMSProp，初始学习速率为0.045，rho=0.9, epsilon=1.0（确定吗？但是论文上是这样写的），decay采用指数衰减，每两个epoch衰减一次。指数衰减的公式如下：decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)  \n",
    "\n",
    "但是我有一个问题，论文中给出的训练的建议是基于ImageNet的训练集，并且作者是训练整体的模型，但是现在是在猫狗数据上进行训练，而且并没有对整体的模型进行训练，那我们是否应该采用论文中的建议的训练方式，下面尝试一下就知道了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "with h5py.File(inceptionv3_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "Epoch 0 , new lr==0.000200\n",
      "20000/20000 [==============================] - 6s 286us/step - loss: 0.1802 - acc: 0.9615 - val_loss: 0.0443 - val_acc: 0.9910\n",
      "Epoch 2/30\n",
      "Epoch 1 , new lr==0.000200\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0378 - acc: 0.9918 - val_loss: 0.0289 - val_acc: 0.9920\n",
      "Epoch 3/30\n",
      "Epoch 2 , new lr==0.000188\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0293 - acc: 0.9924 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "Epoch 4/30\n",
      "Epoch 3 , new lr==0.000188\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0256 - acc: 0.9924 - val_loss: 0.0233 - val_acc: 0.9928\n",
      "Epoch 5/30\n",
      "Epoch 4 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 0.0241 - acc: 0.9931 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 6/30\n",
      "Epoch 5 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0215 - val_acc: 0.9936\n",
      "Epoch 7/30\n",
      "Epoch 6 , new lr==0.000166\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0211 - val_acc: 0.9936\n",
      "Epoch 8/30\n",
      "Epoch 7 , new lr==0.000166\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0214 - acc: 0.9936 - val_loss: 0.0208 - val_acc: 0.9940\n",
      "Epoch 9/30\n",
      "Epoch 8 , new lr==0.000156\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 10/30\n",
      "Epoch 9 , new lr==0.000156\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0205 - val_acc: 0.9940\n",
      "Epoch 11/30\n",
      "Epoch 10 , new lr==0.000147\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 12/30\n",
      "Epoch 11 , new lr==0.000147\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0204 - val_acc: 0.9940\n",
      "Epoch 13/30\n",
      "Epoch 12 , new lr==0.000138\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 14/30\n",
      "Epoch 13 , new lr==0.000138\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 0.0206 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 15/30\n",
      "Epoch 14 , new lr==0.000130\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 16/30\n",
      "Epoch 15 , new lr==0.000130\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9946\n",
      "Epoch 17/30\n",
      "Epoch 16 , new lr==0.000122\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 18/30\n",
      "Epoch 17 , new lr==0.000122\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.0188 - acc: 0.9939 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 19/30\n",
      "Epoch 18 , new lr==0.000115\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 20/30\n",
      "Epoch 19 , new lr==0.000115\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 21/30\n",
      "Epoch 20 , new lr==0.000108\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9942\n",
      "Epoch 22/30\n",
      "Epoch 21 , new lr==0.000108\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 23/30\n",
      "Epoch 22 , new lr==0.000101\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0201 - val_acc: 0.9944\n",
      "Epoch 24/30\n",
      "Epoch 23 , new lr==0.000101\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0201 - val_acc: 0.9942\n",
      "Epoch 25/30\n",
      "Epoch 24 , new lr==0.000095\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0198 - acc: 0.9937 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 26/30\n",
      "Epoch 25 , new lr==0.000095\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 27/30\n",
      "Epoch 26 , new lr==0.000089\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0199 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 28/30\n",
      "Epoch 27 , new lr==0.000089\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9946\n",
      "Epoch 29/30\n",
      "Epoch 28 , new lr==0.000084\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 30/30\n",
      "Epoch 29 , new lr==0.000084\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.0193 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9942\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='inc_dense_1')(x)\n",
    "\n",
    "inceptionv3_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "#optimizer\n",
    "#lr_base = 0.045\n",
    "lr_base = 0.0002\n",
    "decay_rate = 0.94\n",
    "decay_steps = 2\n",
    "#opt = RMSprop(lr=lr_base, rho=0.9, epsilon=1.0)\n",
    "opt = RMSprop(lr=lr_base, rho=0.9)\n",
    "\n",
    "# exponential rate decay:decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)\n",
    "def lr_scheduler(epoch):\n",
    "    # calculate the new learning rate according to epoch number\n",
    "    lr = lr_base * ((decay_rate)**math.floor(epoch/decay_steps))\n",
    "    print (\"Epoch %d , new lr==%f\" % (epoch, lr))    \n",
    "    \n",
    "    return lr\n",
    "\n",
    "scheduler = LearningRateScheduler(lr_scheduler)\n",
    "inceptionv3_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = inceptionv3_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.2, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "可以看到，如果按照论文上的训练方法训练效果还是很不错的，现在就来看看该模型的评分吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "test result file inceptionv3.csv generated!\n"
     ]
    }
   ],
   "source": [
    "get_test_result(inceptionv3_model, inceptionv3_vec_path, (299, 299), model_name=\"inceptionv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交kaggle之后，发现获得的分数为0.04074，在leaderboard中可以排名到第17名，也就是在2%以内。同样，我们保存该模型与权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_model.save('model_inceptionv3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 xception\n",
    "接下来我将尝试xception模型，出了预处理函数和图片上输出尺寸需要改动外，其他均和上述过程一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import xception\n",
    "\n",
    "xception_vec_path = 'vect/xception.h5'\n",
    "\n",
    "if not isfile(xception_vec_path):\n",
    "    model_vector_catch(xception.Xception, (299, 299), 'xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(xception_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练方式，我还是选择与inceptionv3一样的训练方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='xce_dense_1')(x)\n",
    "\n",
    "xception_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "#optimizer\n",
    "#lr_base = 0.045\n",
    "lr_base = 0.0002\n",
    "decay_rate = 0.94\n",
    "decay_steps = 2\n",
    "#opt = RMSprop(lr=lr_base, rho=0.9, epsilon=1.0)\n",
    "opt = RMSprop(lr=lr_base, rho=0.9)\n",
    "\n",
    "# exponential rate decay:decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)\n",
    "def lr_scheduler(epoch):\n",
    "    # calculate the new learning rate according to epoch number\n",
    "    lr = lr_base * ((decay_rate)**math.floor(epoch/decay_steps))\n",
    "    print (\"Epoch %d , new lr==%f\" % (epoch, lr))    \n",
    "    \n",
    "    return lr\n",
    "\n",
    "scheduler = LearningRateScheduler(lr_scheduler)\n",
    "xception_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = xception_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.2, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化fit过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_result(xception_model, xception_vec_path, (299, 299), model_name=\"xception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xception在测试集上的分数是0.04138，结果和inceptionv3差不多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型的集成\n",
    "\n",
    "我们知道，在机器学习中有一种技巧叫做集成学习，不知道其是否适用于深度学习，集成学习的思想就是三个臭皮匠顶个诸葛亮，让多个模型来进行投票，遵循少数服从多数的原则来产生预测结果，可以使预测结果更加平滑，准确，坏处就是可能会增加预测的时间，但是既然kaggle没有提到有模型预测时间的要求，那么我们就可以尝试一些集成学习。\n",
    "\n",
    "在这里我简单地尝试一下uniform blending的集成方式，然后采用取三个模型的输出值的平均值作为集成的最终输出（而不是所谓的‘投票’，因为kaggle需要输出概率值而不是投票结果）。\n",
    "\n",
    "注意：uniform blending集成方法的假设是我们的三个基准模型本身拥有diversity，这样才会有好的结果。我不清楚我的这三个模型知否符合这样的要求。而且集成方法的效果总是会随着基准模型的数量的增多而变好，所以我也不清楚3个模型到底够不够。既然不懂，就尝试嘛！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建集成模型，由于网络结构比较简答，就没有必要像之前的bottleneck features那样预先保存向量了，直接将之前训练好的三个模型的输出层合并求平均就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('The name \"res_dense_1\" is used 2 times in the model. All layer names should be unique. Layer names: ', ['input_4', 'input_6', 'dropout_2', 'dropout_3', 'res_dense_1', 'res_dense_1', 'average_2'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9dce822b2bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0magg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minceptionv3_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxception_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0magg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresnet50_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minceptionv3_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxception_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1827\u001b[0m                                    \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                                    \u001b[0;34m'All layer names should be unique. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m                                    'Layer names: ', all_names)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;31m# Layer parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ('The name \"res_dense_1\" is used 2 times in the model. All layer names should be unique. Layer names: ', ['input_4', 'input_6', 'dropout_2', 'dropout_3', 'res_dense_1', 'res_dense_1', 'average_2'])"
     ]
    }
   ],
   "source": [
    " from keras.layers import Average\n",
    "\n",
    "## resnet_50\n",
    "resnet50_input = res_top_model.input\n",
    "resnet50_output = res_top_model.output\n",
    "\n",
    "##inception_v3\n",
    "inceptionv3_input = inceptionv3_model.input\n",
    "inceptionv3_output = inceptionv3_model.output\n",
    "\n",
    "##xception\n",
    "xception_input = xception_model.input\n",
    "xception_output = xception_model.output\n",
    "\n",
    "#agg_out = (resnet50_output + inceptionv3_output + xception_output)/3\n",
    "#agg_out = K.divide(K.add(K.add(resnet50_output, inceptionv3_output), xception_output), 3.0)\n",
    "agg_out = Average()([resnet50_output, inceptionv3_output, xception_output])\n",
    "\n",
    "agg_model = Model(inputs=[resnet50_input, inceptionv3_input, xception_input], outputs=agg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个函数，方便获取各个不同基准模型的bottleneck features。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_features(path):\n",
    "    ## get bottleneck features\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        x_train = np.array(f['x_train'])\n",
    "        y_train = np.array(f['y_train'])\n",
    "        x_test = np.array(f['test'])\n",
    "        return x_train,  y_train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在再获取各个基准模型的bottleneck features，作为集成模型的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## resnet 50\n",
    "res_x_train, res_y_train, res_test = get_bottleneck_features(resnet_50_vec_path)\n",
    "\n",
    "## inception v3\n",
    "inc_x_train, inc_y_train, inc_test = get_bottleneck_features(inceptionv3_vec_path)\n",
    "\n",
    "## xception\n",
    "xce_x_train, xce_y_train, xce_test = get_bottleneck_features(xception_vec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为没有任何参数需要优化，所以无需训练，我们现在evaluation来看看结果如何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_model.evaluate([res_x_train, inc_x_train, xce_x_train], res_y_train, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
