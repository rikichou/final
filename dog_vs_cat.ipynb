{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1，数据集准备\n",
    "\n",
    "\n",
    "数据集来自kaggle的dog vs cat主页（https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riki/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "data_path = './'\n",
    "train_dir_name = 'train'\n",
    "test_dir_name = 'test'\n",
    "\n",
    "## check if the train and  test data is exist\n",
    "if not isdir(data_path + train_dir_name):\n",
    "    if not isfile(data_path + train_dir_name + '.zip'):\n",
    "        print (\"Please download train.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(data_path + train_dir_name + '.zip') as azip:\n",
    "            print (\"Now to extract %s \" % (data_path + train_dir_name + '.zip'))\n",
    "            azip.extractall()\n",
    "    \n",
    "if not isdir(data_path + test_dir_name):\n",
    "    if not isfile(data_path + test_dir_name + '.zip'):\n",
    "        print (\"Please download test1.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(data_path + test_dir_name + '.zip') as azip:\n",
    "            print (\"Now to extract %s \" % (data_path + test_dir_name + '.zip'))\n",
    "            azip.extractall()\n",
    "print (\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1，将猫狗训练数据分开存放\n",
    "\n",
    "为了尽快实现想法，我打算采用Keras平台，因为Keras已经包含了众多知名的模型，并且可以很轻易地加载与训练权重。而且Keras也提供了很方便的工具（image generator）来帮助我们直接从硬盘加载图片到模型，这样不但减少了代码量，而且利用Keras自带的程序能够极大减少内存的浪费（相比于手动一次性加载到内存）。但是image generator需要图片已经根据类别放入不同的文件夹。所以接下来的事情就是将训练和测试样本按照类别放入不同的文件夹。采用软链接的方式可以节约硬盘和时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = data_path + train_dir_name\n",
    "test_dir = data_path + test_dir_name\n",
    "\n",
    "## get all train filenames and test filenames\n",
    "train_filenames = os.listdir(train_dir)\n",
    "test_filenames = os.listdir(test_dir)\n",
    "\n",
    "## get all dogs and cats\n",
    "cat_names = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "dog_names = filter(lambda x:x[:3] == 'dog', train_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在已经获得了文件名，现在需要另外建立一个文件夹，用于存储分开的猫狗图片。为了节省空间，这里采用建立软链接的方式来分开存储猫狗图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build all linkage complete!\n"
     ]
    }
   ],
   "source": [
    "## check if we did that\n",
    "test_link_path = './test_link'\n",
    "test_link_data = './test_link/data'\n",
    "\n",
    "train_link_path = './train_link'\n",
    "train_link_cat = './train_link/cat'\n",
    "train_link_dog = './train_link/dog'\n",
    "\n",
    "if not isdir(test_link_path):\n",
    "    print (\"Now to build %s!\" % (test_link_path))\n",
    "    os.makedirs(test_link_path)\n",
    "    os.symlink('../' + test_dir_name, test_link_data)\n",
    "    \n",
    "if not isdir(train_link_path):\n",
    "    print (\"Now to build %s!\" % (train_link_path))\n",
    "    os.makedirs(train_link_cat)\n",
    "    os.makedirs(train_link_dog)\n",
    "    ## create link for the image\n",
    "    for file in cat_names:\n",
    "        os.symlink('../../' + train_dir_name+'/'+file, train_link_cat+'/'+file)\n",
    "    for file in dog_names:\n",
    "        os.symlink('../../' + train_dir_name+'/'+file, train_link_dog+'/'+file)\n",
    "\n",
    "print (\"Build all linkage complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, 方案1--单个模型\n",
    "\n",
    "首先我想到的第一个方案就是单个模型，在计算机视觉领域，有许多已经被证明了非常好用的模型，比如inception，resnet等，所以我接下来就是依次尝试各个模型，看看实际的效果怎么样？能否达到毕业项目的要求？并且我会预训练模型来进行训练，而不是从头训练，因为这些模型都已经在庞大的分类数据集中进行了训练，已经学习了足够的用于常用物体分类的‘知识’，因为图像的基本‘知识’是可以通用的，所以我采用迁移学习来对模型进行‘微调’，而不是从头学起。我打算采用inceptionv3,resnet-50,xception这三个模型来进行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 resnet-50\n",
    "\n",
    "初步采用的模型是ResNet-50，所以我们就需要按照该模型的要求来对图片进行预处理。\n",
    "现在我们需要载入预训练的ResNet-50模型，并且，由于ResNet-50模型的输出是1000维的向量，而我们的功能是二分类，所以只需要输出单一的概率即可，所以需要替换掉原始的输出层换成我们的sigmoid激活函数，include_top=False就不会加载原模型的全连接层部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"avg_pool/AvgPool:0\", shape=(?, 1, 1, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import resnet50\n",
    "\n",
    "## resNet-50 do not need preprocessing, so the resNet_input_shape is not neccessary\n",
    "resNet_input_shape = (224,224,3)\n",
    "\n",
    "res_x = Input(shape=resNet_input_shape)\n",
    "res_x = Lambda(resnet50.preprocess_input)(res_x)\n",
    "res_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=res_x, input_shape=resNet_input_shape)\n",
    "\n",
    "print (res_model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们采用的预训练模型，暂时只是在ResNet-50上微调，不会对全连接层以外的其它层进行训练。所以如果每次都从上面的模型的输入端进行输入的话会产生很多重复的计算，显得不那么高效。那么这里有一个技巧，可以先把resnet-50模型的全连接层以前的输出向量（传说中的bottleneck features，以下均称为特征向量）预先计算并保存起来，由于只需要训练之后的全连接层，所以，将这些保存的特征向量作为样本，当做之后的全连接层的训练的输入就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./vect\n",
      "Make vector dir:./vect\n",
      "creating vector!!\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "vec_dir_name = \"vect/\"\n",
    "resnet_50_vec_name = 'resnet-50.h5'\n",
    "vec_dir_path = data_path + \"vect\"\n",
    "resnet_50_vec_path = data_path + vec_dir_name + resnet_50_vec_name\n",
    "print (vec_dir_path)\n",
    "if not isdir(vec_dir_path):\n",
    "    os.makedirs(vec_dir_path)\n",
    "    print (\"Make vector dir:%s\" % (vec_dir_path))\n",
    "    \n",
    "\"\"\"\n",
    "check if the resnet-50 vector file is exist\n",
    "\"\"\"\n",
    "if not isfile(resnet_50_vec_path):\n",
    "    with h5py.File(resnet_50_vec_path, 'w') as f:\n",
    "        print (\"creating vector!!\")\n",
    "        out = GlobalAveragePooling2D()(res_model.output)\n",
    "        res_vec_model = Model(inputs=res_model.input, outputs=out)\n",
    "        \n",
    "        ## save vector\n",
    "        gen = ImageDataGenerator()\n",
    "        test_gen = ImageDataGenerator()\n",
    "        \"\"\"\n",
    "        classes = ['cat', 'dog'] -- cat is 0, dog is 1, so we need write this\n",
    "        class_mode = None -- i will not use like 'fit_fitgenerator', so i do not need labels\n",
    "        shuffle = False -- it is unneccssary\n",
    "        batch_size = 64 \n",
    "        \"\"\"\n",
    "        image_size = (224,224)\n",
    "        train_generator = gen.flow_from_directory(train_link_path, image_size, color_mode='rgb', \\\n",
    "                                                  classes=['cat', 'dog'], class_mode=None, shuffle=False, batch_size=64)\n",
    "        test_generator = test_gen.flow_from_directory(test_link_path, image_size, color_mode='rgb', \\\n",
    "                                                  class_mode=None, shuffle=False, batch_size=64)        \n",
    "        \"\"\"\n",
    "        steps = None, by default, the steps = len(generator)\n",
    "        \"\"\"\n",
    "        vector = res_vec_model.predict_generator(train_generator)\n",
    "        test_vector = res_vec_model.predict_generator(test_generator)\n",
    "        \n",
    "        f.create_dataset('x_train', data=vector)\n",
    "        f.create_dataset(\"y_train\", data=train_generator.classes)\n",
    "        f.create_dataset(\"test\", data=test_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "现在直接读取保存的特征向量进行训练，参数如下，优化器采用Adam，学习速率采用默认的0.001，batch size为32，先训练20epoch看看结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 224us/step - loss: 0.0775 - acc: 0.9719 - val_loss: 0.0340 - val_acc: 0.9882\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0397 - acc: 0.9864 - val_loss: 0.0306 - val_acc: 0.9886\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0354 - acc: 0.9877 - val_loss: 0.0345 - val_acc: 0.9892\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0367 - acc: 0.9859 - val_loss: 0.0350 - val_acc: 0.9878\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0329 - acc: 0.9882 - val_loss: 0.0311 - val_acc: 0.9894\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0318 - acc: 0.9893 - val_loss: 0.0269 - val_acc: 0.9910\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0308 - acc: 0.9897 - val_loss: 0.0314 - val_acc: 0.9882\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0302 - val_acc: 0.9894\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0323 - acc: 0.9884 - val_loss: 0.0297 - val_acc: 0.9896\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0320 - acc: 0.9889 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0315 - acc: 0.9893 - val_loss: 0.0292 - val_acc: 0.9896\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9894\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0302 - acc: 0.9899 - val_loss: 0.0345 - val_acc: 0.9882\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0335 - acc: 0.9884 - val_loss: 0.0335 - val_acc: 0.9896\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0297 - acc: 0.9893 - val_loss: 0.0304 - val_acc: 0.9892\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0303 - acc: 0.9890 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0342 - acc: 0.9884 - val_loss: 0.0325 - val_acc: 0.9896\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0294 - acc: 0.9901 - val_loss: 0.0408 - val_acc: 0.9868\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0311 - acc: 0.9896 - val_loss: 0.0348 - val_acc: 0.9890\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "with h5py.File(resnet_50_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.4)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='res_dense_1')(x)\n",
    "\n",
    "res_top_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "res_top_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = res_top_model.fit(x_train, y_train, batch_size=32, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的结果看起来还不错，待会儿再在测试集上得出结果提交到kaggle。其实在得到这个结果之前犯了一个错误，就是从文件中读取出来x_train和y_train之后，没有对样本进行shuffle。导致验证集的loss在0.2到0.7不断地跳动，我刚开始还以为只是模型的结构引起的过拟合，所以修改了dropout的rate，将其变大，也就是丢弃的几率变大。而且还在输出层对参数加了一个L2的正则化。但是几乎没有效果。所以我就意识到，可能不是模型的问题。然后在群上看他们聊天聊到shuffle，我恍然大悟，原来是我读出来的时候没有进行shuffle，现在就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_loss(hist, title='loss'):\n",
    "    # show the training and validation loss\n",
    "    plt.plot(hist.history['val_loss'], label=\"validation loss\")\n",
    "    plt.plot(hist.history['loss'], label=\"train loss\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def show_acc(hist, title='accuracy'):\n",
    "    # show the training and validation loss\n",
    "    plt.plot(hist.history['val_acc'], label=\"validation accuracy\")\n",
    "    plt.plot(hist.history['acc'], label=\"train accuracy\")\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练完了之后，应该对测试集进行预测，并且声称csv格式的结果文件提交kaggle，从而得到模型的得分。其实文档的格式很简单，就是对测试集的每张图片的预测结果（也就是这张图片是狗的概率，注意不是0或者1哟！是类似0.99  0.11之类的概率值！），我写了一个专门的接口函数来完成预测以及结果文件的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "test result file resnet-50.csv generated!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_test_result(model_obj, test_vec_path, image_size, model_name=\"\"):\n",
    "    with h5py.File(test_vec_path, 'r') as f:\n",
    "        x_test = np.array(f['test'])\n",
    "\n",
    "    pred_test = model_obj.predict(x_test)\n",
    "    pred_test = pred_test.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    df = pd.read_csv(\"sampleSubmission.csv\")\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    test_generator = gen.flow_from_directory(test_link_path, image_size, color_mode='rgb',\n",
    "                                             shuffle=False, batch_size=64, class_mode=None)\n",
    "\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "        #df.set_value(index-1, 'label', y_pred[i])\n",
    "        df.loc[index-1, 'label'] = pred_test[i]\n",
    "    \n",
    "    df.to_csv('%s.csv' % (model_name), index=None)\n",
    "    print ('test result file %s.csv generated!' % (model_name))\n",
    "    df.head(10)\n",
    "\n",
    "get_test_result(res_top_model, resnet_50_vec_path, (224, 224), model_name=\"resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次提交了kaggle之后，loss为0.053。resnet-50模型先暂时不试了。先把模型参数和参数保存起来。由于是预训练模型，所以就不需要保存resnet-50部分，只保存添加的输出层参数就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_top_model.save('resnet-50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 inceptionv3\n",
    "\n",
    "接下尝试的是inceptionv3模型。因为以后还会尝试更多的模型，所以这里需要写一个通用的函数，而不是像之前resnet那样很分散。下面这个函数用于各种模型的特征向量的提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "def model_vector_catch(MODEL, image_size, file_name, preprocessing=None):\n",
    "    vec_dir = 'vect/'\n",
    "\n",
    "    input_tensor = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    if preprocessing:\n",
    "        ## check if need preprocessing\n",
    "        input_tensor = Lambda(preprocessing)(input_tensor)\n",
    "    model_no_top = MODEL(include_top=False, weights='imagenet', input_tensor=input_tensor, input_shape=(image_size[0], image_size[1], 3))\n",
    "    ## flatten the output shape and generate model\n",
    "    out = GlobalAveragePooling2D()(model_no_top.output)\n",
    "    new_model = Model(inputs=model_no_top.input, outputs=out)\n",
    "    \n",
    "    ## get iamge generator\n",
    "    gen = ImageDataGenerator()\n",
    "    test_gen = ImageDataGenerator()\n",
    "    \"\"\"\n",
    "    classes = ['cat', 'dog'] -- cat is 0, dog is 1, so we need write this\n",
    "    class_mode = None -- i will not use like 'fit_fitgenerator', so i do not need labels\n",
    "    shuffle = False -- it is unneccssary\n",
    "    batch_size = 64 \n",
    "    \"\"\"\n",
    "    train_generator = gen.flow_from_directory(train_link_path, image_size, color_mode='rgb', \\\n",
    "                                              classes=['cat', 'dog'], class_mode=None, shuffle=False, batch_size=64)\n",
    "    test_generator = test_gen.flow_from_directory(test_link_path, image_size, color_mode='rgb', \\\n",
    "                                          class_mode=None, shuffle=False, batch_size=64)\n",
    "    \"\"\"\n",
    "    steps = None, by default, the steps = len(generator)\n",
    "    \"\"\"\n",
    "    train_vector = new_model.predict_generator(train_generator)\n",
    "    test_vector = new_model.predict_generator(test_generator)\n",
    "    \n",
    "    with h5py.File(vec_dir + (\"%s.h5\" % (file_name)), 'w') as f: \n",
    "        f.create_dataset('x_train', data=train_vector)\n",
    "        f.create_dataset(\"y_train\", data=train_generator.classes)\n",
    "        f.create_dataset(\"test\", data=test_vector)\n",
    "    print (\"Model %s vector cached complete!\" % (file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Model inceptionv3 vector cached complete!\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "\n",
    "#if not isfile('vect/inceptionv3.h5'):\n",
    "model_vector_catch(inception_v3.InceptionV3, (299, 299), 'inceptionv3', inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，我们先搭建模型，然后进行迁移学习。由于inceptionv3在全连接层之前的输出维度是(?, 1, 1, 2048)，所以新搭建的模型的输入维度是2048.\n",
    "\n",
    "inception v3论文上说其训练时候采用的是RMSProp，初始学习速率为0.045，rho=0.9, epsilon=1.0（确定吗？但是论文上是这样写的），decay采用指数衰减，每两个epoch衰减一次。指数衰减的公式如下：decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)  \n",
    "\n",
    "但是我有一个问题，论文中给出的训练的建议是基于ImageNet的训练集，并且作者是训练整体的模型，但是现在是在猫狗数据上进行训练，而且并没有对整体的模型进行训练，那我们是否应该采用论文中的建议的训练方式，下面尝试一下就知道了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "inceptionv3_vec_path = 'vect/inceptionv3.h5'\n",
    "\n",
    "with h5py.File(inceptionv3_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "Epoch 0 , new lr==0.000200\n",
      "20000/20000 [==============================] - 5s 229us/step - loss: 0.1449 - acc: 0.9613 - val_loss: 0.0439 - val_acc: 0.9888\n",
      "Epoch 2/30\n",
      "Epoch 1 , new lr==0.000200\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0407 - acc: 0.9898 - val_loss: 0.0305 - val_acc: 0.9908\n",
      "Epoch 3/30\n",
      "Epoch 2 , new lr==0.000188\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0317 - acc: 0.9911 - val_loss: 0.0266 - val_acc: 0.9910\n",
      "Epoch 4/30\n",
      "Epoch 3 , new lr==0.000188\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0283 - acc: 0.9916 - val_loss: 0.0243 - val_acc: 0.9914\n",
      "Epoch 5/30\n",
      "Epoch 4 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0268 - acc: 0.9923 - val_loss: 0.0236 - val_acc: 0.9914\n",
      "Epoch 6/30\n",
      "Epoch 5 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0262 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9918\n",
      "Epoch 7/30\n",
      "Epoch 6 , new lr==0.000166\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0225 - val_acc: 0.9920\n",
      "Epoch 8/30\n",
      "Epoch 7 , new lr==0.000166\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0236 - val_acc: 0.9910\n",
      "Epoch 9/30\n",
      "Epoch 8 , new lr==0.000156\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 10/30\n",
      "Epoch 9 , new lr==0.000156\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0239 - acc: 0.9931 - val_loss: 0.0228 - val_acc: 0.9914\n",
      "Epoch 11/30\n",
      "Epoch 10 , new lr==0.000147\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0218 - val_acc: 0.9924\n",
      "Epoch 12/30\n",
      "Epoch 11 , new lr==0.000147\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0214 - val_acc: 0.9922\n",
      "Epoch 13/30\n",
      "Epoch 12 , new lr==0.000138\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0219 - acc: 0.9928 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "Epoch 14/30\n",
      "Epoch 13 , new lr==0.000138\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0213 - val_acc: 0.9918\n",
      "Epoch 15/30\n",
      "Epoch 14 , new lr==0.000130\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0213 - val_acc: 0.9922\n",
      "Epoch 16/30\n",
      "Epoch 15 , new lr==0.000130\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0223 - acc: 0.9937 - val_loss: 0.0214 - val_acc: 0.9920\n",
      "Epoch 17/30\n",
      "Epoch 16 , new lr==0.000122\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0220 - acc: 0.9933 - val_loss: 0.0216 - val_acc: 0.9924\n",
      "Epoch 18/30\n",
      "Epoch 17 , new lr==0.000122\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0229 - acc: 0.9936 - val_loss: 0.0213 - val_acc: 0.9920\n",
      "Epoch 19/30\n",
      "Epoch 18 , new lr==0.000115\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0216 - acc: 0.9933 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 20/30\n",
      "Epoch 19 , new lr==0.000115\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0213 - acc: 0.9934 - val_loss: 0.0212 - val_acc: 0.9922\n",
      "Epoch 21/30\n",
      "Epoch 20 , new lr==0.000108\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0217 - val_acc: 0.9922\n",
      "Epoch 22/30\n",
      "Epoch 21 , new lr==0.000108\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0213 - val_acc: 0.9918\n",
      "Epoch 23/30\n",
      "Epoch 22 , new lr==0.000101\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0211 - acc: 0.9940 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 24/30\n",
      "Epoch 23 , new lr==0.000101\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0213 - val_acc: 0.9920\n",
      "Epoch 25/30\n",
      "Epoch 24 , new lr==0.000095\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9920\n",
      "Epoch 26/30\n",
      "Epoch 25 , new lr==0.000095\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 0.0222 - acc: 0.9936 - val_loss: 0.0214 - val_acc: 0.9920\n",
      "Epoch 27/30\n",
      "Epoch 26 , new lr==0.000089\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0210 - acc: 0.9937 - val_loss: 0.0214 - val_acc: 0.9920\n",
      "Epoch 28/30\n",
      "Epoch 27 , new lr==0.000089\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.0214 - val_acc: 0.9920\n",
      "Epoch 29/30\n",
      "Epoch 28 , new lr==0.000084\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0216 - val_acc: 0.9918\n",
      "Epoch 30/30\n",
      "Epoch 29 , new lr==0.000084\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.0217 - val_acc: 0.9918\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='res_dense_1')(x)\n",
    "\n",
    "inceptionv3_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "#optimizer\n",
    "#lr_base = 0.045\n",
    "lr_base = 0.0002\n",
    "decay_rate = 0.94\n",
    "decay_steps = 2\n",
    "#opt = RMSprop(lr=lr_base, rho=0.9, epsilon=1.0)\n",
    "opt = RMSprop(lr=lr_base, rho=0.9)\n",
    "\n",
    "# exponential rate decay:decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)\n",
    "def lr_scheduler(epoch):\n",
    "    # calculate the new learning rate according to epoch number\n",
    "    lr = lr_base * ((decay_rate)**math.floor(epoch/decay_steps))\n",
    "    print (\"Epoch %d , new lr==%f\" % (epoch, lr))    \n",
    "    \n",
    "    return lr\n",
    "\n",
    "scheduler = LearningRateScheduler(lr_scheduler)\n",
    "inceptionv3_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = inceptionv3_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.2, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8XXWd7//XZ2fvZOfWJG3T0itJC5S2UNpSSrGUiyjTygzIyHVAgaMyOjKOPz0e6w2RczyDM/wQdRgVjzAoKHJwUJRqFSmg80BoC6WllF4opU0vaXpJmvttf84fayVN0yR7t8nO9f18sB/rvvZ3dZP93t/vWuu7zN0RERHpSWSgCyAiIoOfwkJERJJSWIiISFIKCxERSUphISIiSSksREQkKYWFyEkysx1m9r6BLodIf1BYiIhIUgoLERFJSmEh0ktmlmVm95vZnvB1v5llhcvGmtlvzKzSzA6Z2Z/MLBIu+4KZ7TazajPbbGaXDeyRiHQvOtAFEBkGvgwsAuYCDvwK+ArwVeBzQBlQHK67CHAzmwHcAZzn7nvMrATI6N9ii6RONQuR3rsJuNvd97t7BfB14MPhsmZgAnCquze7+5886JCtFcgCZplZzN13uPvbA1J6kRQoLER6byLwbofpd8N5AP8KbAN+b2bbzWw5gLtvAz4D3AXsN7PHzWwiIoOUwkKk9/YAp3aYnhrOw92r3f1z7j4NuBL4bNu5CXf/qbtfGG7rwDf7t9giqVNYiPTez4CvmFmxmY0F7gQeBTCzvzaz08zMgCqC5qeEmc0ws/eGJ8IbgHogMUDlF0lKYSHSe/8LWAOsBzYAr4bzAE4HngVqgJeAf3f3VQTnK+4BDgD7gHHAF/u32CKpMz38SEREklHNQkREklJYiIhIUgoLERFJSmEhIiJJDZvuPsaOHeslJSUDXQwRkSFl7dq1B9y9ONl6wyYsSkpKWLNmzUAXQ0RkSDGzd5OvpWYoERFJgcJCRESSUliIiEhSw+achYj0v+bmZsrKymhoaBjookgS8XicyZMnE4vFTmp7hYWInLSysjLy8/MpKSkh6CtRBiN35+DBg5SVlVFaWnpS+1AzlIictIaGBsaMGaOgGOTMjDFjxvSqBqiwEJFeUVAMDb39nBQWDUdg1T9D2dqBLomIyKClsEi0wAv3QNkrA10SEekHeXl5AOzZs4drrrmmy3UuueSSpDf53n///dTV1bVPf+ADH6CysrLX5bvrrru49957e72fvqawiBcEw4aqgS2HiPSriRMn8uSTT5709p3DYsWKFRQWFvZF0QYlhUUkA7JGKSxEhqDly5fzwAMPtE+3/SqvqanhsssuY/78+Zx99tn86le/Om7bHTt2cNZZZwFQX1/PDTfcwMyZM7n66qupr69vX++Tn/wkCxYsYPbs2Xzta18D4Dvf+Q579uzh0ksv5dJLLwWCLocOHDgAwH333cdZZ53FWWedxf3339/+fjNnzuTjH/84s2fP5vLLLz/mfbqybt06Fi1axJw5c7j66qs5fPhw+/vPmjWLOXPmcMMNNwDwwgsvMHfuXObOncu8efOorq4+qX/T7ujSWQhqF/W9rz6KjGRf//VG3txzpE/3OWviKL72N7O7XX799dfzmc98hk996lMAPPHEE6xcuZJ4PM5TTz3FqFGjOHDgAIsWLeLKK6/s9iTv9773PXJycti0aRPr169n/vz57cu+8Y1vMHr0aFpbW7nssstYv349n/70p7nvvvtYtWoVY8eOPWZfa9eu5eGHH+bll1/G3Tn//PO5+OKLKSoqYuvWrfzsZz/jhz/8Iddddx2/+MUvuPnmm7s9vo985CN897vf5eKLL+bOO+/k61//Ovfffz/33HMP77zzDllZWe1NX/feey8PPPAAixcvpqamhng8nvK/cypUs4AgLFSzEBly5s2bx/79+9mzZw+vv/46RUVFTJkyBXfnS1/6EnPmzOF973sfu3fvpry8vNv9vPjii+1f2nPmzGHOnDnty5544gnmz5/PvHnz2LhxI2+++WaPZfrzn//M1VdfTW5uLnl5efzt3/4tf/rTnwAoLS1l7ty5AJx77rns2LGj2/1UVVVRWVnJxRdfDMAtt9zCiy++2F7Gm266iUcffZRoNPjNv3jxYj772c/yne98h8rKyvb5fSWtNQszWwp8G8gA/o+739Np+UXA/cAc4AZ3f7LT8lHAm8Av3f2OtBVUYSHSaz3VANLp2muv5cknn2Tfvn1cf/31ADz22GNUVFSwdu1aYrEYJSUlJ3WPwTvvvMO9997L6tWrKSoq4tZbb+3VvQpZWVnt4xkZGUmbobrzzDPP8OKLL/LrX/+ab3zjG2zYsIHly5dzxRVXsGLFChYvXszKlSs588wzT7qsnaWtZmFmGcADwDJgFnCjmc3qtNpO4Fbgp93s5n8CL6arjO3ihdCgZiiRoej666/n8ccf58knn+Taa68Fgl/l48aNIxaLsWrVKt59t+deuC+66CJ++tPga+iNN95g/fr1ABw5coTc3FwKCgooLy/nt7/9bfs2+fn5XZ4XWLJkCb/85S+pq6ujtraWp556iiVLlpzwcRUUFFBUVNReK/nJT37CxRdfTCKRYNeuXVx66aV885vfpKqqipqaGt5++23OPvtsvvCFL3Deeefx1ltvnfB79iSdNYuFwDZ33w5gZo8DVxHUFABw9x3hskTnjc3sXGA88DtgQRrLqZqFyBA2e/ZsqqurmTRpEhMmTADgpptu4m/+5m84++yzWbBgQdJf2J/85Ce57bbbmDlzJjNnzuTcc88F4JxzzmHevHmceeaZTJkyhcWLF7dvc/vtt7N06VImTpzIqlWr2ufPnz+fW2+9lYULFwLwsY99jHnz5vXY5NSdRx55hE984hPU1dUxbdo0Hn74YVpbW7n55pupqqrC3fn0pz9NYWEhX/3qV1m1ahWRSITZs2ezbNmyE36/npi79+kO23dsdg2w1N0/Fk5/GDi/q+YkM/sP4DdtzVBmFgGeA24G3gcs6Ga724HbAaZOnXpusl8P3frtclj3GHxx18ltLzJCbdq0iZkzZw50MSRFXX1eZrbW3ZP+IB+sJ7j/AVjh7mU9reTuD7r7AndfUFyc9KmA3csuhMYjkGg9+X2IiAxj6WyG2g1M6TA9OZyXiguAJWb2D0AekGlmNe6+vI/LGOh4Y17O6LS8hYjIUJbOsFgNnG5mpQQhcQPwd6ls6O43tY2b2a0EzVDpCQpQWIiIJJG2Zih3bwHuAFYCm4An3H2jmd1tZlcCmNl5ZlYGXAv8wMw2pqs8PYqHt+jrJLeISJfSep+Fu68AVnSad2eH8dUEzVM97eM/gP9IQ/GOaq9Z6PJZEZGuDNYT3P1LnQmKiPRIYQEKC5EhqrKykn//938/qW1PtEvxwdp1eH9RWEBw6SyoM0GRIaansGhpaelx2+HepXhfU1gAZOaBRVSzEBlili9fzttvv83cuXP5/Oc/z/PPP8+SJUu48sormTUr6F3ogx/8IOeeey6zZ8/mwQcfbN+2rUvxod51eH9RF+UAZuryQ6S3frsc9m3o232ecjYsu6fbxffccw9vvPEG69atA+D555/n1Vdf5Y033qC0tBSAhx56iNGjR1NfX895553Hhz70IcaMGXPMfoZy1+H9RTWLNupMUGRYWLhwYXtQQPBr/5xzzmHRokXs2rWLrVu3HrfNUO46vL8MzVKng2oWIr3TQw2gP+Xm5raPP//88zz77LO89NJL5OTkcMkll3TZxfhQ7jq8v6hm0UZhITLkdNdNeJuqqiqKiorIycnhrbfe4i9/+Uuv33OwdR3eX1SzaJNdCPuH5ocoMlKNGTOGxYsXc9ZZZ7Fs2TKuuOKKY5YvXbqU73//+8ycOZMZM2awaNGiPnnfwdR1eH9JWxfl/W3BggW+Zs2ak9/B0/8IW34P/31z3xVKZJhTF+VDy3Dsorz/qRlKRKRbCos28UJoqYeWxoEuiYjIoKOwaKMuP0ROynBpyh7uevs5KSzaqJtykRMWj8c5ePCgAmOQc3cOHjzYqxsCdTVUG9UsRE7Y5MmTKSsro6KiYqCLIknE43EmT+7xiRA9Uli0UWeCIicsFosdc7e0DF9qhmqjByCJiHRLYdFGzVAiIt1SWLRpP8GtmoWISGcKizaxOGRkqWYhItIFhUVHuotbRKRLCouOsgt1NZSISBfSGhZmttTMNpvZNjNb3sXyi8zsVTNrMbNrOsyfa2YvmdlGM1tvZtens5ztVLMQEelS2sLCzDKAB4BlwCzgRjOb1Wm1ncCtwE87za8DPuLus4GlwP1mlv4nqyssRES6lM6b8hYC29x9O4CZPQ5cBbzZtoK77wiXJTpu6O5bOozvMbP9QDGQ3jaieAEceietbyEiMhSlsxlqErCrw3RZOO+EmNlCIBN4u4/K1T09h1tEpEuD+gS3mU0AfgLc5u6JLpbfbmZrzGxNn/RN09YMpU7RRESOkc6w2A1M6TA9OZyXEjMbBTwDfNndu3xwrrs/6O4L3H1BcXFxrwoLBGGRaIHmut7vS0RkGElnWKwGTjezUjPLBG4Ank5lw3D9p4Afu/uTaSzjsdSZoIhIl9IWFu7eAtwBrAQ2AU+4+0Yzu9vMrgQws/PMrAy4FviBmW0MN78OuAi41czWha+56SprO/UPJSLSpbR2Ue7uK4AVnebd2WF8NUHzVOftHgUeTWfZuqSwEBHp0qA+wd3v1JmgiEiXFBYdqWYhItIlhUVHeg63iEiXFBYdxUcFQ4WFiMgxFBYdZcQgM0+XzoqIdKKw6EydCYqIHEdh0Vm8QFdDiYh0orDoLF6omoWISCcKi85UsxAROY7CojOdsxAROY7CorPsQqhXWIiIdKSw6CxeAI1HIHHc4zNEREYshUVn8QLAg8AQERFAYXG89v6hdJJbRKSNwqIz9Q8lInIchUVn6nlWROQ4CovOFBYiIsdRWHSm53CLiBxHYdGZahYiIsdRWHSWmQ+YwkJEpAOFRWeRiPqHEhHpRGHRFfUPJSJyDIVFVxQWIiLHSGtYmNlSM9tsZtvMbHkXyy8ys1fNrMXMrum07BYz2xq+bklnOY+TXairoUREOkhbWJhZBvAAsAyYBdxoZrM6rbYTuBX4aadtRwNfA84HFgJfM7OidJX1OKpZiIgcI501i4XANnff7u5NwOPAVR1XcPcd7r4e6NzF618Bf3D3Q+5+GPgDsDSNZT2WwkJE5BjpDItJwK4O02XhvD7b1sxuN7M1ZramoqLipAt6nHihroYSEelgSJ/gdvcH3X2Buy8oLi7uux3HC6G5Dlqa+m6fIiJDWDrDYjcwpcP05HBeurftvba7uPVMCxERIL1hsRo43cxKzSwTuAF4OsVtVwKXm1lReGL78nBe/1CXHyIix0hbWLh7C3AHwZf8JuAJd99oZneb2ZUAZnaemZUB1wI/MLON4baHgP9JEDirgbvDef1DnQmKiBwjms6du/sKYEWneXd2GF9N0MTU1bYPAQ+ls3zd0tPyRESOMaRPcKeNmqFERI6hsOhK+6NVVbMQEQGFRddUsxAROYbCoiuxbIjEFBYiIiGFRVfMgtqFroYSEQEUFt3LLlTNQkQkpLDojjoTFBFpp7Dojh6tKiLSTmHRnbiaoURE2igsuqNmKBGRdgqL7rSFhftAl0REZMApLLqTXQitTdBcP9AlEREZcAqL7ugubhGRdgqL7igsRETaKSy6o27KRUTaKSy6Ey8KhqpZiIikFhZm9k9mNsoCPzKzV83s8nQXbkCpGUpEpF2qNYv/5u5HCJ6FXQR8GLgnbaUaDNrCQp0JioikHBYWDj8A/MTdN3aYNzypZiEi0i7VsFhrZr8nCIuVZpYPJNJXrEEgmgmxHJ3gFhEBoimu91FgLrDd3evMbDRwW/qKNUioyw8RESD1msUFwGZ3rzSzm4GvAMP/WzReqJqFiAiph8X3gDozOwf4HPA28OO0lWqwUM1CRARIPSxa3N2Bq4B/c/cHgPxkG5nZUjPbbGbbzGx5F8uzzOzn4fKXzawknB8zs0fMbIOZbTKzL6Z+SH1IYSEiAqQeFtXhF/aHgWfMLALEetrAzDKAB4BlwCzgRjOb1Wm1jwKH3f004FvAN8P51wJZ7n42cC7w921B0q/0HG4RESD1sLgeaCS432IfMBn41yTbLAS2uft2d28CHieomXR0FfBIOP4kcJmZGeBArplFgWygCTiSYln7jp7DLSICpBgWYUA8BhSY2V8DDe6e7JzFJGBXh+mycF6X67h7C8FJ8zEEwVEL7AV2Ave6+6HOb2Bmt5vZGjNbU1FRkcqhnJh4ATQegcTwvkpYRCSZVLv7uA54haB56DrgZTO7Jo3lWgi0AhOBUuBzZjat80ru/qC7L3D3BcXFxX1fingBeAKaqvt+3yIiQ0iq91l8GTjP3fcDmFkx8CxBDaA7u4EpHaYnh/O6WqcsbHIqAA4Cfwf8zt2bgf1m9l/AAmB7iuXtG/HCYNhQdfSObhGRESjVcxaRtqAIHUxh29XA6WZWamaZwA3A053WeRq4JRy/BnguvOpqJ/BeADPLBRYBb6VY1r6jLj9ERIDUaxa/M7OVwM/C6euBFT1t4O4tZnYHsBLIAB5y941mdjewxt2fBn4E/MTMtgGHCAIFgquoHjaztj6oHnb39SdyYH1CnQmKiAAphoW7f97MPgQsDmc96O5PpbDdCjqFirvf2WG8geA8SOftarqa3++yOzRDiYiMYKnWLHD3XwC/SGNZBh81Q4mIAEnCwsyqCe55OG4R4O4+Ki2lGiwUFiIiQJKwcPekXXoMa1kFgKkzQREZ8fQM7p5EIpA1SjULERnxFBbJqDNBERGFRVLqTFBERGGRlDoTFBFRWCSlZigREYVFUvECXQ0lIiOewiKZuJqhREQUFsnEC6CpBlpbBrokIiIDRmGRjO7iFhFRWCTV3pmgzluIyMilsEhGNQsREYVFUgoLERGFRVLtYaFmKBEZuRQWycT1ACQREYVFMmqGEhFRWCSVmQuWoc4ERWREU1gkY6bOBEVkxFNYpEKdCYrICKewSIU6ExSRES6tYWFmS81ss5ltM7PlXSzPMrOfh8tfNrOSDsvmmNlLZrbRzDaYWTydZe2ROhMUkREubWFhZhnAA8AyYBZwo5nN6rTaR4HD7n4a8C3gm+G2UeBR4BPuPhu4BGhOV1mTUjOUiIxw6axZLAS2uft2d28CHgeu6rTOVcAj4fiTwGVmZsDlwHp3fx3A3Q+6e2say9ozPVpVREa4dIbFJGBXh+mycF6X67h7C1AFjAHOANzMVprZq2b2P9JYzuRUsxCRES460AXoRhS4EDgPqAP+aGZr3f2PHVcys9uB2wGmTp2avtJkF0JrIzQ3QGzgTp2IiAyUdNYsdgNTOkxPDud1uU54nqIAOEhQC3nR3Q+4ex2wApjf+Q3c/UF3X+DuC4qLi9NwCCHdxS0iI1w6w2I1cLqZlZpZJnAD8HSndZ4GbgnHrwGec3cHVgJnm1lOGCIXA2+msaw9i+uZFiIysqWtGcrdW8zsDoIv/gzgIXffaGZ3A2vc/WngR8BPzGwbcIggUHD3w2Z2H0HgOLDC3Z9JV1mTUmeCIjLCpfWchbuvIGhC6jjvzg7jDcC13Wz7KMHlswNPzVAiMsLpDu5UtIWFLp8VkRFKYZEKPYdbREY4hUUqskYFQzVDicgIpbBIRSwO0bhqFiIyYiksUqW7uEVkBFNYpEo9z4rICKawSJVqFiIygiksUqWeZ0VkBFNYpErP4RaREUxhkSo1Q4nICKawSFVbWLgPdElERPqdwiJV8ULwVmiqGeiSiIj0O4VFqtSZoIiMYAqLVKkzQREZwRQWqcrWMy1EZORSWKRKzVAiMoIpLFLVHhZqhhKRkUdhkSo9WlVERjCFRar0TAsRGcFGfFjsq2rgtodfYfWOQz2vmBGFzHyFhYiMSCM+LAqyY2zYXcW3n92afGV1JigiI9SID4vszAxuv2gaf952gLXvJqldqDNBERmhRnxYANy86FTG5Gby7T9u63lFdSYoIiNUWsPCzJaa2WYz22Zmy7tYnmVmPw+Xv2xmJZ2WTzWzGjP77+ksZ05mlI9fNI0Xt1Tw2s7D3a8YL9ClsyIyIqUtLMwsA3gAWAbMAm40s1mdVvsocNjdTwO+BXyz0/L7gN+mq4wdfXjRqYzOzeTbf+zh3EW8EOoOqudZERlx0lmzWAhsc/ft7t4EPA5c1Wmdq4BHwvEngcvMzADM7IPAO8DGNJaxXW5WlI8tKeX5zRWs29VN7WHq+VC9F155sD+KJCIyaKQzLCYBuzpMl4XzulzH3VuAKmCMmeUBXwC+3tMbmNntZrbGzNZUVFT0usAfuaCEwpwY3+mudjH/FjhjKfz+K7DntV6/n4jIUDFYT3DfBXzL3Xt8eIS7P+juC9x9QXFxca/fNC8ryscuLOW5t/azvqyL2oUZfPB7kFsM//c2aDjS6/cUERkK0hkWu4EpHaYnh/O6XMfMokABcBA4H/gXM9sBfAb4kpndkcaytrvlPSUUZPdQu8gZDR/6EVTuhN98RucvRGRESGdYrAZON7NSM8sEbgCe7rTO08At4fg1wHMeWOLuJe5eAtwP/G93/7c0lrVdfjzGRy8s5dlN+3ljdzeXyZ56AVz6JXjjF/Dqj/ujWCIiAyptYRGeg7gDWAlsAp5w941mdreZXRmu9iOCcxTbgM8Cx11eOxBuXVzCqHi0+9oFwIWfhWmXwG//B5S/2V9FExEZEObDpBllwYIFvmbNmj7b3/3PbuH+Z7ey4tNLmDVxVNcrVZfD9y8MmqY+/hxk5vbZ+4uI9AczW+vuC5KtN1hPcA+42xaXkp+sdpE/Hv72QajYHNQwRESGKYVFNwqyY9y2uJTfbdzHpr09XPU0/VJY8jl47VFY/0T/FVBEpB8pLHrw3xaXkJcV5bvPJemR9pIvwtQL4Df/HxxI0r+UiMgQpLDoQWFOJre+p4QVG/axeV919ytmRIPLaTNi8OSt0NzQb2UUEekPCoskPnphKbmZGclrFwWTghv29m2AP3y1fwonItJPFBZJFOVmcst7Snhmw162lvdQuwCYsQwWfSroO+rNzreUiIgMXQqLFHxsyTSyYxl897kUzke87y6YOA9+dQfsfjXdRRMR6RcKixSMzs3kIxeU8Ov1e9i2v8fuqiCaCdc8HJy/+OGl8MQtcCCFR7aKiAxiCosUfXxJKfFoBv+68i2aWhI9rzy6FP5xLVz0edj6B3hgIfzqU0F/UiIiQ5DCIkVj8rL4xMXTWbmxnGXffpEXtyTpEj27EN77Ffin1+H8TwT3YHz3XPjtF6Bmf/8UWkSkj6i7jxP03Fvl3P3rN9lxsI7LZ43nq389iymjc5JvWLkLXvwXeO0xiMZh0SfhPf8YhIqIyABJtbsPhcVJaGxp5Ud/fod/e24bLQnnExdN45OXnEZ2ZkbyjQ9shVX/Gzb+Z/BM78WfgfP/Xv1KiciAUFj0g71V9fzzird4+vU9TCrM5stXzGTZWacQPhk2ycbr4bn/BVtXQiwHJs6HKefB5IUwZSHkjk3/AYjIiKew6EevvHOIrz29kU17j/Ce6WO468rZnDE+P7WNd74cPBej7JXghr5ESzC/qDQIjcnnBcNxs4M7xUVE+pDCop+1tCb42Ss7uff3W6hpbOHDi07l4xdNY1Jhduo7aaqDvetg1ytQtjp41ZQHy2K5wf0bhVODWkdu8bHDnLHBMHYC7yciI57CYoAcrm3i3t9v5qev7MQd5k8t5Io5E/nA2acwoeAEv8jdg8tty1YHAbLnVajeF1xN1drY9TaZeUFoFJXC9PfC6ZdD8Yzg+eEiIp0oLAbYuwdr+c36vfxm/d72Ls4XnFrEFXMm8IGzJzB+VPzkd+4OTTVQWwG1B8NhBdQdgNoDwfi+N6BiU7B+wRQ47X1w+vuh9GLIyuuDIxSR4UBhMYi8XVHDivV7eWbDXt7aV40ZnHfqaK6YM4FlZ53CuN4ER08qd8G2P8DWZ+GdF4KAycgMulM//f1w2vtV6xAZ4RQWg9S2/dU8s34fz2zYw5byGsxg9sRRTC7MYUJhnIkF2UwojDOhIJtJhdkU52eREemDL/OWJtj50tHwaKt1jJoMeeOC7kkiseAkeiQWTkeDcGkbjxcEd6ePng5jpsOoSRBJ4XLhrrhDQyW0NkPOmJPfj4j0isJiCNhSXs1v1u/ltZ2H2VvVwN7KemqbWo9ZJxoxxo+KM6EgzoTCIEAmFx19TSrMSe3+js7aah3v/Akaq6G1KbgSq7UZEs14azMtzU00NzXS2tJEoqWZ7NYjZHrT0X1kZAbnRkZPC8Jj9LTgVXQqNNUGzyiv3gs1+4LxzsO28y4WCQIjb3xwwj5vXPDKHRfMyysOhqMm6SZGkT6msBiC3J0jDS3srapnb2UDe6rq2VPZcbyBvVX1NLce+5mNzcsMQySHSWGIjMvPIh7LIDuWQXZmMIx3Gm+rsRysaWRzeTVb9lWzubyGLeXVbCmvprqhpf09ivOzME8QqdlHaWQfZ2Uf5PxRlczI3M+45j1kHtmBtfTw0Kd4AeSdguePpzFezJHoGCoootVijM84wmivIlZfEZy8r9kPtfuhq/1lFUDhlOA8TOGU4OqwtvGC8EqxgWpWa66H3WuDWlh2UfCKFwadS6ZDIhEE76F34PA7wRBgwhyYMDf4t1EToyShsBimEglnf3UjZYfr2F1ZT9nhesoO11F2uJ7dh+spq6xP3tFhKDMaIRaxY2ozBdkxZozP54xT8oJh+CrKzcTdeedALX/Zfoi/bD/IX7YfZH91UDsYlxfjr6Y6F489wuycKhoi2expLWBHYz5b63LZUZVoL2tDc9flO2VUnGnFuUwvzmP62BxOL4TTcusopopIbTlUlUHVrqBWVLkzGG/s9Hz0aDaMmnj0suKcMcdeZtxxOmdM0MTWG0f2wJaVsOV3sP0FaKk/fp1Y7tHwyC4MX0WQNSq4ITOW3WHY8RXOi8SC92kLhLZh5bvHBqqFNUwPP894IUw4BybODYYT5gY1wcgAdwlXdygod94p/VuW1mYofyO4+KO1KQxS634IkDMaxs0MfogM9L9bmihtm060AAANlklEQVQsRqhEwjlQ28iB6ibqm1tpbG6lvu3V1EpD+3iC+uZWmloSTCyMM+OUfGaMzw9qECn+GnV3dhysaw+Ol94+Gh4dFebEgmazwqM1n8lFOUwuyiYjYmyvqOHtilreDofbK2qOqdVkxzIoGZvL2LxM8uNR8rNijMqOkh+PMTajjnGJCsa2llPYtI/8hr3E6suh9gCRugNEGw6R2XiICMcHVALjYGwCFdnTqcw/ndqiGbSMmUlkzHQK8rIpyI5RmBOjIDtGdiwj+HdJJGDva0cDYu/r4UFOhTOWwWmXQSSK1x+mtfYQibpDeH0lXncY6g9jDYex+koijZVEGo8QaT2xR/C2ZGRTlzeV5vyptBaWwOhSomOnk1k8jZyxJcFx7t8YlGvPumC4/83gyxGCgDplTlD7yBkTXGqdmRtcIdc23nGYlReElhmJhFNV38yhuiYq65o4XHt0/FBtM0camsmKRsjPipIXjzIq6pzS/C7j6t6mqGYL+VVbiB/eTLR2X/D/TzSbpoISGvJLqM07lSM5U6mMT+FA1mQOWxF1zQkamhPEYxFysqLkZWWQmxklNyt45WVlkJsVJSczSm5mUFNubEnQ2JygobmF5kM7iexeS2zfWuLlr5Fz6A0yurvkPInWWC6NRTOob3+dQV3RmbRkjeZEv0NbEk5jS4Km8NXYEvwdNrUmaG5sYOyhtUw68F+ccmQ9dRmjOJw5gUOx8RyMncKBjFOoyBjPEcun1Z3mVqc14ZSOzeWrfz3rpI5tUISFmS0Fvg1kAP/H3e/ptDwL+DFwLnAQuN7dd5jZ+4F7gEygCfi8uz/X03spLAZeW3is23WY/KwYk0cH51jy4yf2693dqahpZHtbgOyvZcfBWg7XNXGkvpnqhhaqG1qob25NvjPASFBALWPsCBNjNUyM1TIhWsO4SBWTmt/l1JYdTPG9ZFjwt9DoMbb6JDb7FN5KTGGzTyGLZi6LvMp7M9YxzippdeM1P4NVPp9Viflss8kYhhm0tDotiVT/rpwsmonTRDaNZFswjNNEPBzPshb2JYrY6eM5wCjaf/V2ISsaISNiRMyIGGREjExaOC1Sxizfzkzfzgx/h+m+gzhN3e6no1YiHCGXykQuVeRS6XnhMJiu8jxqLA8yc5jYuofSxLucaTuZZnuJWiL8N42y1Sez2aewKTGVBjI51copsX2U2j6mWjmZdvTzrPUs3vVT2OHjqfJc6ohTQ5w6j1NLnFqPU8fR8VrijLEjzLNtzI1sY15kG8VWBUCDx3jDS1mXmM5ridPZ4KXUeyZB/cHDV4dxCz4XwymmihmRXZxhZZxpu5gR2cloO/pMm/1eyFuJKWzxyWz1yWxNTGKbT+QIqV+ePsXKuTiynksi63hP5E1yrJFGj7LBp5NnDUyy/eRzbI21jjjlkfGUR8ZRER1P/ehZXHf7l1N+z44GPCzMLAPYArwfKANWAze6+5sd1vkHYI67f8LMbgCudvfrzWweUO7ue8zsLGClu0/q6f0UFiNPc2uC6oaW9gA50tBMdUMzLQknLytKfjxKXlaMvHiUvKzg12c0o+umBG+qo37vJhrKNpAo30hGxSayD79FvOFoV/SNGbnsKLyAt4suZHvhBdRFC3GCC7scJ/yPaMSIZkTIzAiGsYwIsQwjlhEhGrFwOpgXj2WQFY2QFcsgHouQFQ2m2+dHI0QzIjS2tFLT0EJtYyvVjc3UNrZS09hMTWMwv228sbmVhDutCUi4h+NOwoNaZ8KdVncSCSeSaCIzUR+8WuvIaq0n0+vIaq0jM1FPVmsdWV5PHnUUWS0F1JLnNeQmqom3HCHWXEVG4xGMY79DvGAKrcWzaRg9g5qCGRzOO50D8SnUNkN1Qws1jS20JpyczCg5mcF5tNyoUdBcTkHdu+TV7iRevYPMqnfIqHoXb6iCplqsqfa49+pKVc5UDhbOoWr0OdQUz6Vp9Eyy4tnEY8G/a2Y0gju0JBK0JoJgb004LeGv9JZEgoQH0wl3zCwIEzMiOFmNFeRVbSWvagt5VVvIrdxMTtU2MjrUEpvixdQVTKdu1HTqCk4LX9NpjhcTSzQx5uBqiva8wKiyF8is2g5Aa8GptE5/H3b6+4lOW4J1vB+qvjJoeu3y9S6ccjbctiLlv52OBkNYXADc5e5/FU5/EcDd/7nDOivDdV4ysyiwDyj2DoWyoE3kIDDB3butQyosJC3qDkH5xqAde/LC9J2sHqoSieC8Uf3h4D6ewqnBxQzpeq+W+uBKu8bqYNhUG7xvUw1k5sOk+cF5hv6WaA2+uA9sgYrNwetAOOx4Xi1eAC2NwTmbaBxKlhy9YXb0tJO/IKG5AWInd79WqmGRzp7pJgG7OkyXAed3t467t5hZFTAGONBhnQ8Br3YVFGZ2O3A7wNSpU/uu5CJtckZD6ZKBLsXgFYkcPWnfH++VmRu88sal//1ORCQjvAepFM74q6Pz3YMueireOhok0SyYfhmULO67vtxOMihOxKDuxtTMZgPfBC7varm7Pwg8CEHNoh+LJiKSnBmMmhC8pl860KXplXReC7YbmNJhenI4r8t1wmaoAoImJ8xsMvAU8BF3fzuN5RQRkSTSGRargdPNrNTMMoEbgKc7rfM0cEs4fg3wnLu7mRUCzwDL3f2/0lhGERFJQdrCwt1bgDuAlcAm4Al332hmd5vZleFqPwLGmNk24LPA8nD+HcBpwJ1mti58DbJGShGRkUM35YmIjGCpXg01PO9fFxGRPqWwEBGRpBQWIiKSlMJCRESSGjYnuM2sAni3F7sYy7F3jg91w+14YPgd03A7Hhh+xzTcjgeOP6ZT3b042UbDJix6y8zWpHJFwFAx3I4Hht8xDbfjgeF3TMPteODkj0nNUCIikpTCQkREklJYHPXgQBegjw2344Hhd0zD7Xhg+B3TcDseOMlj0jkLERFJSjULERFJSmEhIiJJjfiwMLOlZrbZzLaZ2fLkWwx+ZrbDzDaEvfUOud4VzewhM9tvZm90mDfazP5gZlvDYdFAlvFEdXNMd5nZ7g49K39gIMt4IsxsipmtMrM3zWyjmf1TOH9Ifk49HM9Q/oziZvaKmb0eHtPXw/mlZvZy+J338/AREsn3N5LPWZhZBrAFeD/BY19XAze6+5sDWrBeMrMdwAJ3H5I3E5nZRUAN8GN3Pyuc9y/AIXe/Jwz1Inf/wkCW80R0c0x3ATXufu9Alu1kmNkEYIK7v2pm+cBa4IPArQzBz6mH47mOofsZGZDr7jVmFgP+DPwTweMg/tPdHzez7wOvu/v3ku1vpNcsFgLb3H27uzcBjwNXDXCZRjx3fxE41Gn2VcAj4fgjBH/IQ0Y3xzRkufted381HK8meGbNJIbo59TD8QxZHqgJJ2Phy4H3Ak+G81P+jEZ6WEwCdnWYLmOI/w8ScuD3ZrbWzG4f6ML0kfHuvjcc3weMH8jC9KE7zGx92Ew1JJpsOjOzEmAe8DLD4HPqdDwwhD8jM8sws3XAfuAPwNtAZfhwOjiB77yRHhbD1YXuPh9YBnwqbAIZNjxoOx0O7affA6YDc4G9wP8/sMU5cWaWB/wC+Iy7H+m4bCh+Tl0cz5D+jNy91d3nApMJWlLOPNl9jfSw2A1M6TA9OZw3pLn77nC4H3iK4H+Soa48bFdua1/eP8Dl6TV3Lw//mBPADxlin1PYDv4L4DF3/89w9pD9nLo6nqH+GbVx90pgFXABUGhm0XBRyt95Iz0sVgOnh1cHZAI3AE8PcJl6xcxywxN0mFkucDnwRs9bDQlPA7eE47cAvxrAsvSJti/V0NUMoc8pPHn6I2CTu9/XYdGQ/Jy6O54h/hkVm1lhOJ5NcCHPJoLQuCZcLeXPaERfDQUQXgp3P5ABPOTu3xjgIvWKmU0jqE0ARIGfDrVjMrOfAZcQdKVcDnwN+CXwBDCVoCv669x9yJww7uaYLiFo3nBgB/D3Hdr7BzUzuxD4E7ABSISzv0TQzj/kPqcejudGhu5nNIfgBHYGQcXgCXe/O/yOeBwYDbwG3OzujUn3N9LDQkREkhvpzVAiIpIChYWIiCSlsBARkaQUFiIikpTCQkREklJYiAwCZnaJmf1moMsh0h2FhYiIJKWwEDkBZnZz+IyAdWb2g7Cjthoz+1b4zIA/mllxuO5cM/tL2AndU22d0JnZaWb2bPicgVfNbHq4+zwze9LM3jKzx8K7ikUGBYWFSIrMbCZwPbA47JytFbgJyAXWuPts4AWCu7MBfgx8wd3nENwZ3Db/MeABdz8HeA9BB3UQ9HT6GWAWMA1YnPaDEklRNPkqIhK6DDgXWB3+6M8m6CgvAfw8XOdR4D/NrAAodPcXwvmPAP837Ldrkrs/BeDuDQDh/l5x97Jweh1QQvDAGpEBp7AQSZ0Bj7j7F4+ZafbVTuudbB86HfvnaUV/nzKIqBlKJHV/BK4xs3HQ/rzpUwn+jtp68fw74M/uXgUcNrMl4fwPAy+ET2ErM7MPhvvIMrOcfj0KkZOgXy4iKXL3N83sKwRPIYwAzcCngFpgYbhsP8F5DQi6f/5+GAbbgdvC+R8GfmBmd4f7uLYfD0PkpKjXWZFeMrMad88b6HKIpJOaoUREJCnVLEREJCnVLEREJCmFhYiIJKWwEBGRpBQWIiKSlMJCRESS+n/S+Hl9p2115QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "可以看到，如果按照论文上的训练方法训练效果还是很不错的，现在就来看看该模型的评分吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "test result file inceptionv3.csv generated!\n"
     ]
    }
   ],
   "source": [
    "get_test_result(inceptionv3_model, inceptionv3_vec_path, (299, 299), model_name=\"inceptionv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交kaggle之后，发现获得的分数为0.04074，在leaderboard中可以排名到第17名，也就是在2%以内。同样，我们保存该模型与权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inceptionv3_model.save('model_inceptionv3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 xception\n",
    "接下来我将尝试xception模型，出了预处理函数和图片上输出尺寸需要改动外，其他均和上述过程一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Model xception vector cached complete!\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import xception\n",
    "\n",
    "model_vector_catch(xception.Xception, (299, 299), 'xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xception_vec_path = 'vect/xception.h5'\n",
    "\n",
    "with h5py.File(xception_vec_path, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练方式，我还是选择与inceptionv3一样的训练方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "Epoch 0 , new lr==0.000200\n",
      "20000/20000 [==============================] - 6s 280us/step - loss: 0.1639 - acc: 0.9734 - val_loss: 0.0450 - val_acc: 0.9902\n",
      "Epoch 2/30\n",
      "Epoch 1 , new lr==0.000200\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0379 - acc: 0.9914 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "Epoch 3/30\n",
      "Epoch 2 , new lr==0.000188\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0287 - acc: 0.9924 - val_loss: 0.0254 - val_acc: 0.9922\n",
      "Epoch 4/30\n",
      "Epoch 3 , new lr==0.000188\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 0.0260 - acc: 0.9923 - val_loss: 0.0235 - val_acc: 0.9926\n",
      "Epoch 5/30\n",
      "Epoch 4 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.0225 - val_acc: 0.9930\n",
      "Epoch 6/30\n",
      "Epoch 5 , new lr==0.000177\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.0218 - val_acc: 0.9934\n",
      "Epoch 7/30\n",
      "Epoch 6 , new lr==0.000166\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0231 - acc: 0.9931 - val_loss: 0.0213 - val_acc: 0.9938\n",
      "Epoch 8/30\n",
      "Epoch 7 , new lr==0.000166\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0212 - acc: 0.9937 - val_loss: 0.0211 - val_acc: 0.9940\n",
      "Epoch 9/30\n",
      "Epoch 8 , new lr==0.000156\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0208 - val_acc: 0.9940\n",
      "Epoch 10/30\n",
      "Epoch 9 , new lr==0.000156\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0214 - acc: 0.9940 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 11/30\n",
      "Epoch 10 , new lr==0.000147\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0206 - val_acc: 0.9940\n",
      "Epoch 12/30\n",
      "Epoch 11 , new lr==0.000147\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0204 - val_acc: 0.9940\n",
      "Epoch 13/30\n",
      "Epoch 12 , new lr==0.000138\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 14/30\n",
      "Epoch 13 , new lr==0.000138\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0215 - acc: 0.9936 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 15/30\n",
      "Epoch 14 , new lr==0.000130\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 16/30\n",
      "Epoch 15 , new lr==0.000130\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 17/30\n",
      "Epoch 16 , new lr==0.000122\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 18/30\n",
      "Epoch 17 , new lr==0.000122\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 19/30\n",
      "Epoch 18 , new lr==0.000115\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 20/30\n",
      "Epoch 19 , new lr==0.000115\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 0.0203 - acc: 0.9941 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 21/30\n",
      "Epoch 20 , new lr==0.000108\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "Epoch 22/30\n",
      "Epoch 21 , new lr==0.000108\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 23/30\n",
      "Epoch 22 , new lr==0.000101\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 24/30\n",
      "Epoch 23 , new lr==0.000101\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 25/30\n",
      "Epoch 24 , new lr==0.000095\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0189 - acc: 0.9946 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 26/30\n",
      "Epoch 25 , new lr==0.000095\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0197 - acc: 0.9946 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 27/30\n",
      "Epoch 26 , new lr==0.000089\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 0.0202 - acc: 0.9943 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 28/30\n",
      "Epoch 27 , new lr==0.000089\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.0202 - val_acc: 0.9942\n",
      "Epoch 29/30\n",
      "Epoch 28 , new lr==0.000084\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0200 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9946\n",
      "Epoch 30/30\n",
      "Epoch 29 , new lr==0.000084\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 0.0195 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9942\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "    \n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid', name='res_dense_1')(x)\n",
    "\n",
    "xception_model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "#optimizer\n",
    "#lr_base = 0.045\n",
    "lr_base = 0.0002\n",
    "decay_rate = 0.94\n",
    "decay_steps = 2\n",
    "#opt = RMSprop(lr=lr_base, rho=0.9, epsilon=1.0)\n",
    "opt = RMSprop(lr=lr_base, rho=0.9)\n",
    "\n",
    "# exponential rate decay:decayed_learning_rate = lr_base * decay_rate ^ (global_step / decay_steps)\n",
    "def lr_scheduler(epoch):\n",
    "    # calculate the new learning rate according to epoch number\n",
    "    lr = lr_base * ((decay_rate)**math.floor(epoch/decay_steps))\n",
    "    print (\"Epoch %d , new lr==%f\" % (epoch, lr))    \n",
    "    \n",
    "    return lr\n",
    "\n",
    "scheduler = LearningRateScheduler(lr_scheduler)\n",
    "xception_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = xception_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.2, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化fit过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_loss(hist)\n",
    "show_acc(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_test_result(xception_model, xception_vec_path, (299, 299), model_name=\"xception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xception在测试集上的分数是。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型的集成\n",
    "\n",
    "我们知道，在机器学习中有一种技巧叫做集成学习，不知道其是否适用于深度学习，集成学习的思想就是三个臭皮匠顶个诸葛亮，让多个模型来进行投票，遵循少数服从多数的原则来产生预测结果，可以使预测结果更加平滑，准确，坏处就是可能会增加预测的时间，但是既然kaggle没有提到有模型预测时间的要求，那么我们就可以尝试一些集成学习。\n",
    "\n",
    "在这里我简单地尝试一下uniform blending的集成方式，然后采用取三个模型的输出值的平均值作为集成的最终输出（而不是所谓的‘投票’，因为kaggle需要输出概率值而不是投票结果）。\n",
    "\n",
    "注意：uniform blending集成方法的假设是我们的三个基准模型本身拥有diversity，这样才会有好的结果。我不清楚我的这三个模型知否符合这样的要求。而且集成方法的效果总是会随着基准模型的数量的增多而变好，所以我也不清楚3个模型到底够不够。既然不懂，就尝试嘛！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建集成模型，由于网络结构比较简答，就没有必要像之前的bottleneck features那样预先保存向量了，直接将之前训练好的三个模型的输出层合并求平均就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## resnet_50\n",
    "resnet50_input = res_top_model.input\n",
    "resnet50_output = res_top_model.output\n",
    "\n",
    "##inception_v3\n",
    "inceptionv3_input = inceptionv3_model.input\n",
    "inceptionv3_output = inceptionv3_model.output\n",
    "\n",
    "##xception\n",
    "xception_input = xception_model.input\n",
    "xception_output = xception_model.output\n",
    "\n",
    "agg_out = (resnet50_output + inceptionv3_output + xception_output)/3\n",
    "\n",
    "agg_model = Model(inputs=[resnet50_input, inceptionv3_input, xception_input], outputs=agg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个函数，方便获取各个不同基准模型的bottleneck features。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottleneck_features(path):\n",
    "    ## get bottleneck features\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        x_train = np.array(f['x_train'])\n",
    "        y_train = np.array(f['y_train'])\n",
    "        x_test = np.array(f['test'])\n",
    "        return x_train,  y_train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在再获取各个基准模型的bottleneck features，作为集成模型的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## resnet 50\n",
    "res_x_train, res_y_train, res_test = get_bottleneck_features(resnet_50_vec_path)\n",
    "\n",
    "## inception v3\n",
    "inc_x_train, inc_y_train, inc_test = get_bottleneck_features(inceptionv3_vec_path)\n",
    "\n",
    "## xception\n",
    "xce_x_train, xce_y_train, xce_test = get_bottleneck_features(xception_vec_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为没有任何参数需要优化，所以无需训练，我们现在evaluation来看看结果如何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_model.evaluate([res_x_train, inc_x_train, xce_x_train], res_y_train, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
